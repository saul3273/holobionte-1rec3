# Nu Framework: Autonomous Multi-Agent Orchestrator

Nu = Cerebro aut√≥nomo del Holobionte basado en browser-use + AsyncIO + Ollama

## üß† Visi√≥n: Arquitectura Nativa Python

**Browser-use** = Automatizaci√≥n web moderna y potente
**AsyncIO** = Orquestaci√≥n paralela nativa de Python
**Ollama** = Razonamiento local sin censura

**No es solo automatizaci√≥n**: Es AGENCIA real
- Puede planificar tareas de m√∫ltiples pasos
- Puede reflexionar sobre resultados  
- Puede adaptarse a errores
- Puede tomar decisiones aut√≥nomas

---

## üéÆ Arquitectura Multi-Navegador

```
         NU (Cerebro)
           ‚îú‚îÄ AsyncIO Orchestrator
           ‚îú‚îÄ Ollama Reasoning
           ‚îî‚îÄ Task Queue Manager
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         ‚îÇ         ‚îÇ
        ‚ñº         ‚ñº         ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇBrowser‚îÇ  ‚îÇBrowser‚îÇ  ‚îÇBrowser‚îÇ
   ‚îÇ Worker‚îÇ  ‚îÇ Worker‚îÇ  ‚îÇ Worker‚îÇ
   ‚îÇ#1 (FLR)‚îÇ  ‚îÇ#2 (UPK)‚îÇ  ‚îÇ#3 (GH) ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ         ‚îÇ         ‚îÇ
  Freelancer  Upwork   GitHub
   bidding   bidding automation
```

Cada Browser-Use worker puede:
- Actuar en paralelo
- Tomar decisiones locales
- Reportar a Nu
- Recibir new tasks

---

## üîÑ Ciclo de Nu

**1. PERCEPCI√ìN**
```
Browsers reportan: "He visto esto en Freelancer"
Ollama procesa: "Esto significa que..."
```

**2. RAZONAMIENTO**
```
Ollama piensa:
"Necesito:
- Bid en este proyecto
- Esperar respuesta en GitHub  
- Actualizar memoria en Qdrant"
```

**3. PLANEACI√ìN**
```
AsyncIO genera plan:
Task 1: Browser #1 -> Login Freelancer + Search
Task 2: Browser #2 -> Check Upwork messages
Task 3: Browser #3 -> Update GitHub
Task 4: Esperar 30 min -> Task 5
```

**4. EJECUCI√ìN PARALELA**
```
Browser #1, #2, #3 act√∫an simult√°neamente
Nu monitorea progreso
Si error: Replanning
```

**5. REFLEXI√ìN**
```
Ollama refleja: "Los bids bajaron porque..."
Guarda insights en Qdrant
Ajusta estrategia para pr√≥xima sesi√≥n
```

---

## üí´ Comparaci√≥n: Nu vs Alternativas

| Aspecto | **Nu (browser-use)** | n8n | Comet |
|---------|---------|-----|-------|
| **Multi-navegador** | ‚úÖ Native | ‚ùå Via plugins | ‚úÖ Limited |
| **Razonamiento** | ‚úÖ Full (Ollama) | ‚ùå Basic | ‚úÖ Good |
| **Autonom√≠a** | ‚úÖ Completa | ‚ùå Limitada | ‚úÖ Good |
| **Local LLM** | ‚úÖ Nativo | ‚ùå Via API | ‚ùå NO |
| **Reflexi√≥n** | ‚úÖ Loop real | ‚ùå NO | ‚úÖ Limited |
| **Costo** | $0 | $0 | $20-240 |
| **Control** | ‚úÖ 100% | ‚úÖ 100% | ‚ùå 0% |
| **AsyncIO Native** | ‚úÖ S√≠ | ‚ùå NO | ‚ùå NO |

---

## üõ¨ Casos de Uso: Multi-Browser Nu

### Caso 1: B√∫squeda de Trabajo Paralela

```
Browser #1 (Freelancer):
  - Busca 10 proyectos
  - Analiza con Ollama
  - Bids autom√°ticos

Browser #2 (Upwork):
  - Busca 10 m√°s
  - Bids en paralelo

Browser #3 (GitHub):
  - Monitorea issues
  - Actualiza logros

= 30 potenciales clientes EN PARALELO
```

### Caso 2: Monitoreo 24/7

```
Browser #1: Checks Freelancer messages (15 min intervals)
Browser #2: Checks Upwork responses (10 min intervals)  
Browser #3: Scrolls Twitter for leads (20 min intervals)
Browser #4: Monitors competitor bids (30 min intervals)

Nu solo interviene si necesario
```

### Caso 3: Content Creation + Bidding

```
Browser #1: Extrae requirements de proyecto
Browser #2: Busca referencias en GitHub/Web
Browser #3: Submits bid while #2 is still researching

= Parallelism total
```

---

## üìÑ Implementaci√≥n Nu Core

```python
import asyncio
from browser_use import BrowserWorker
from ollama import AsyncClient
from qdrant_client import QdrantClient

class Nu:
    def __init__(self):
        self.ollama = AsyncClient()  # Local LLM reasoning
        self.memory = QdrantClient()  # Episodic memory
        self.browsers = []  # Multi-browser pool
        self.task_queue = asyncio.Queue()  # Task coordination
    
    async def create_browser_worker(self, task_domain):
        """Crea nuevo Browser Worker independiente"""
        worker = BrowserWorker(domain=task_domain)
        self.browsers.append(worker)
        return worker
    
    async def perceive(self):
        """Todos los browsers reportan estado"""
        results = await asyncio.gather(
            *[b.get_status() for b in self.browsers]
        )
        return results
    
    async def reason(self, perception):
        """Ollama interpreta percepciones"""
        response = await self.ollama.chat(
            model='deepseek-r1:70b',
            messages=[{
                'role': 'user',
                'content': f"Analiza estos resultados: {perception}"
            }]
        )
        return response['message']['content']
    
    async def plan(self, analysis):
        """AsyncIO genera plan multistep usando Ollama"""
        response = await self.ollama.chat(
            model='deepseek-r1:70b',
            messages=[{
                'role': 'user',
                'content': f"Genera plan de acci√≥n para: {analysis}"
            }]
        )
        # Parse plan into tasks
        plan = self._parse_plan(response['message']['content'])
        return plan
    
    async def execute_parallel(self, tasks):
        """Ejecuta m√∫ltiples tasks en paralelo con AsyncIO"""
        results = await asyncio.gather(
            *[self._assign_task(t) for t in tasks],
            return_exceptions=True
        )
        return results
    
    async def _assign_task(self, task):
        """Asigna task a browser worker disponible"""
        worker = self._get_available_worker()
        return await worker.execute(task)
    
    def _get_available_worker(self):
        """Encuentra worker disponible o crea uno nuevo"""
        for worker in self.browsers:
            if not worker.is_busy():
                return worker
        # Si todos ocupados, usa round-robin
        return self.browsers[len(self.browsers) % len(self.browsers)]
    
    async def orchestrate(self):
        """Main loop: Perceive -> Reason -> Plan -> Execute"""
        while True:
            try:
                # 1. Percibir
                perceptions = await self.perceive()
                
                # 2. Razonar
                analysis = await self.reason(perceptions)
                
                # 3. Planificar
                plan = await self.plan(analysis)
                
                # 4. Ejecutar en paralelo
                results = await self.execute_parallel(plan['tasks'])
                
                # 5. Guardar en memoria
                for r in results:
                    if not isinstance(r, Exception):
                        await self.memory.store(r)
                
                # Loop cada 5 minutos
                await asyncio.sleep(300)
                
            except Exception as e:
                print(f"Error en ciclo Nu: {e}")
                await asyncio.sleep(60)  # Espera 1 min antes de reintentar

# LANZA NU
if __name__ == '__main__':
    nu = Nu()
    
    # Crea 3 browsers
    async def main():
        await nu.create_browser_worker('freelancer')
        await nu.create_browser_worker('upwork')
        await nu.create_browser_worker('github')
        
        # Inicia loop infinito
        await nu.orchestrate()
    
    asyncio.run(main())
```

---

## üö™ Stack Completo Nu

```yaml
Nu:
  core: "AsyncIO + Python 3.11+"
  reasoning: "Ollama (DeepSeek-R1 70B)"
  perception: "browser-use x N workers"
  memory:
    episodic: "Qdrant (vectors)"
    semantic: "Git (structured data)"
    cache: "Redis"
  coordination: "AsyncIO native"
  persistence: "Git + Qdrant"
```

---

## üöÄ Ventajas del Approach browser-use + AsyncIO

‚úÖ **Paralelismo**: N tareas simult√°neamente con AsyncIO nativo
‚úÖ **Resiliencia**: Un browser cae, otros siguen  
‚úÖ **Especializaci√≥n**: Cada browser optimizado para su dominio
‚úÖ **Escalabilidad**: A√±ade workers din√°micamente
‚úÖ **Observabilidad**: Monitor cada worker independiente
‚úÖ **Costos**: $0 - todo local y open source
‚úÖ **Control Total**: No dependencia de APIs externas
‚úÖ **Simplicidad**: AsyncIO es est√°ndar de Python, no frameworks externos

---

## üì¶ Pr√≥ximo: Implementaci√≥n Fase 1

1. ‚úÖ Setup Ollama + DeepSeek-R1 70B
2. ‚è≥ Crear Nu.py core con AsyncIO
3. ‚è≥ Implementar 3 BrowserWorkers (Freelancer, Upwork, GitHub)
4. ‚è≥ Test parallelization con asyncio.gather
5. ‚è≥ Add Qdrant memory layer
6. ‚è≥ Deploy con Docker Compose

---

## üîç Por qu√© browser-use en vez de AutoGPT?

**AutoGPT (2023-2024)**:
- ‚ùå Requiere OpenAI API ($$$)
- ‚ùå Perdi√≥ autonom√≠a en versiones recientes
- ‚ùå Enfoque en cloud, no local-first
- ‚ùå Complejidad innecesaria para nuestro caso de uso

**browser-use + AsyncIO (2025)**:
- ‚úÖ Licencia MIT, $0 de costo
- ‚úÖ Control total del c√≥digo
- ‚úÖ AsyncIO es nativo de Python 3.11+
- ‚úÖ Integraci√≥n directa con Ollama
- ‚úÖ M√°s simple, m√°s r√°pido, m√°s mantenible
- ‚úÖ Local-first por dise√±o
